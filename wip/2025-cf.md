## TODO

- [ ] Refactor `@livestore/sync-cf`
  - [ ] Refactor DO RPC transport streaming implementation to be "poking-to-pull" based
  - [ ] Test deployed example
  - [ ] Make storage (local SQLite vs D1) configurable
  - [ ] Setup otel
  - [ ] Enforce `2KB WebSocket attachment size` limit for DOs
  - [ ] get rid of `enable_request_signal` mentions as we're no longer using it
    - actually, we probably want to keep it for the first pull phase
  - [ ] Potential bug: Sometimes wrangler dev WS server stops accepting new connections. Restarting fixes it but we should figure out the root cause. We need a reliably repro first. Seems to have something to do with the server before getting into a bad state.
  - [ ] Get rid of type casts when fixed https://github.com/cloudflare/workerd/issues/4811
  - [ ] Introduce backendId per store to detect cases where the backend instance is changing (e.g. when reset)
- [ ] CF DO adapter (`@livestore/adapter-cloudflare`)
  - [ ] Support for LiveStore devtools
  - [ ] Bug: "Get stuck" when there's an error in the DO client pull stream https://share.cleanshot.com/QY8c4j7F
  - [ ] Get rid of (or minimize) adapter `polyfill.ts`
  - [ ] Ungraceful error handling when DO/client gets into an inconsistent state (e.g. for a unique constraint violation in the materializer)
      ```
      [19:12:55.160 DoClient] LiveStore.UnexpectedError: { "cause": Error: This should never happen: During boot the backend head (9) should never be greater than the local head (8), "note": undefined, "payload": undefined } LiveStore.UnexpectedError: { "cause": Error: This should never happen: During boot the backend head (9) should never be greater than the local head (8), "note": undefined, "payload": undefined }
      ```
  - [ ] Create CF worker only example (without DO)
  - [ ] Test with multiple stores in a single client DO
- Other discovered bugs / things
  - [ ] Changing the client document schema doesn't seem to trigger a new livestore schema migration
  - [ ] rebase loop https://share.cleanshot.com/15qFnMh9
  - [ ] iterating on the materializers should be considered a schema change and trigger a re-materialization
  - [ ] Once client got into a bad state, it boots with `"During boot the backend head (51) should never be greater than the local head (50)"`. We should prevent it from this happening in the first place.
- Sync provider tests
  - [ ] Write more sync provider tests
  - [ ] Tests for concurrent pulls / sequential pushes
  - [ ] Property-based testing for various non-happy path scenarios / chaos testing
  - [ ] App-level logic in sync backend for rejecting events
  - [ ] Make Electric sync provider tests stateless (i.e. reset docker compose containers between tests)
  - [ ] Test `payload` parameter
  - [ ] Sometimes tests "get stuck" / don't finish
  - [ ] Performance/load testing
- Chat example app
  - [ ] web adapter: Client session sync processor doesn't push to leader
  - [ ] DO adapter: leader doesn't push to backend
- Cleanup work
  - [ ] Figure out why `workerd` process is leaking (causes 99% CPU usage)
  - [ ] Move `supports` into `metadata` in `SyncBackend` type
  - [ ] Rename to `SyncProvider` instead of `SyncBackend`
  - [ ] Align naming of `@livestore/sync-cf` with `@livestore/adapter-cloudflare`
  - [ ] Reduce logs of sync provider tests

## Work notes

- Formed a stronger mental model of how Durable Objects work. Particularly re concurrency and hibernation.
- Tried out paths that didn't end up being viable:
  - HTTP-based streaming (required `enable_request_signal` compatibility flag). Worked but ended up keeping both client and server DOs alive for the whole duration of the pull (-> CPU billing)
  - DO RPC `ReadableStream` transport. Worked but ended up keeping both client and server DOs alive for the whole duration of the pull (-> CPU billing)
- Using DO Sqlite directly wasn't feasible
  - Now: Layered SQLite: using SQLite as Sqlite VFS
- Streaming and hibernatable reactivity are different things
- 2-phase pull streaming:
  - Phase 1: initial pull with all events from db as stream to improve latency. stream closes once all events are sent
  - Phase 2: Reactivity stream for new pushed events
- Core challenge:
  - How to model streaming so it's reactive but also allows for hibernation

## CF issues

- [ ] type compatibility between `cloudflare:workers` and `@cloudflare/workers-types`
- [ ] Otel support
- [ ] Visibility into / APIs for DO hibernation (during local development)

## Future work

### Other explorations

- [ ] Investigate using CF queues

### Cloudflare

- [ ] Allow for Sync DO and client DO to be deployed via separate workers
- [ ] Support for read replicas
- [ ] Enable support for WS transport for hibernated outgoing connections (see [workerd issue](https://github.com/cloudflare/workerd/issues/4864))